{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d267c5c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction margin: the only parameter to set. Margin in {4, 7, 10, 13} (aka 0.3, 0.6, 0.9, 1.2 seconds)\n",
    "margin = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df02c22",
   "metadata": {},
   "source": [
    "## Import libraries and define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3375203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = lambda l: sum(l) / len(l)\n",
    "\n",
    "def describe(l, n_quantiles=10, list_quantiles=None):\n",
    "    print(f'Min={min(l):.4}, Max={max(l):.4}, Avg={mean(l):.4}, Tot={len(l)}')\n",
    "    if list_quantiles is None:\n",
    "        list_quantiles = [e / n_quantiles for e in range(1, n_quantiles)]\n",
    "    for q in list_quantiles:\n",
    "        print(q, \":\", round(np.quantile(l, q), 3))\n",
    "    return min(l), max(l), mean(l), len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b3b931",
   "metadata": {},
   "source": [
    "#### Set up global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d48c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "plt.rcParams['figure.figsize'] = [18, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d37c80",
   "metadata": {},
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_headers = r'data/headers.txt'\n",
    "f_acc = r'data/raw/accelerations.csv'\n",
    "f_pos = r'data/raw/positions.csv'\n",
    "f_labels = r'data/raw/labels_train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55903c8f",
   "metadata": {},
   "source": [
    "## Raw data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f_headers, \"r\") as file:\n",
    "    col_acc = file.readline()[:-1].split(\",\")\n",
    "    col_pos = file.readline()[:-1].split(\",\")\n",
    "    col_lab = file.readline().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.read_csv(f_acc, names=col_acc)\n",
    "pos_df = pd.read_csv(f_pos, names=col_pos)\n",
    "lab_df = pd.read_csv(f_labels, names=col_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df[\"time_server\"] = pd.to_datetime(pos_df[\"time_server\"], format='%Y-%m-%d %H:%M:%S.%f').apply(lambda x: x.timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd5c5c",
   "metadata": {},
   "source": [
    "#### Raw data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afc2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The dataset contains {len(acc_df)} samples')\n",
    "acc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The dataset contains {len(pos_df)} samples')\n",
    "pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689608b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The dataset contains {len(lab_df)} samples')\n",
    "lab_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fdf50b",
   "metadata": {},
   "source": [
    "## Data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value, return_index=True):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    if return_index:\n",
    "        return array[idx], idx\n",
    "    else:\n",
    "        return array[idx]\n",
    "\n",
    "def merge_data(acc, pos, lab):\n",
    "    \n",
    "    delta = 0.05  # data sampling from sensors every 0.1s on average\n",
    "    merged_data = []\n",
    "    disalignments = []\n",
    "    \n",
    "    for i_lab in range(len(lab) - 1):\n",
    "        if lab.loc[i_lab, \"label\"] == \"s\":\n",
    "            start = lab.loc[i_lab, \"time_server\"]\n",
    "            end = lab.loc[i_lab + 1, \"time_server\"]\n",
    "            curr_acc = acc[(acc[\"time_server\"] > start - delta) & (acc[\"time_server\"] < end + delta)]\n",
    "            curr_pos = pos[(pos[\"time_server\"] > start - delta) & (pos[\"time_server\"] < end + delta)]\n",
    "            \n",
    "            for i_acc in range(len(curr_acc)):\n",
    "                curr_data_acc = curr_acc.iloc[i_acc]\n",
    "                curr_time = curr_data_acc[\"time_server\"]\n",
    "                curr_data_acc = curr_data_acc.tolist()\n",
    "                nearest, i_nearest = find_nearest(curr_pos[\"time_server\"].to_numpy(), curr_time)\n",
    "                disalignments.append(np.abs(curr_time - nearest))\n",
    "                curr_data_pos = curr_pos.iloc[i_nearest].tolist()\n",
    "                merged_data.append(curr_data_acc + curr_data_pos + [len(curr_acc) - 1 - i_acc])\n",
    "                \n",
    "            print(f'The {int(i_lab / 2 + 1)}Â° lap lasts for approx. {len(curr_acc) / 10} seconds')\n",
    "        \n",
    "    return merged_data, disalignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data, time_disalignments = merge_data(acc_df, pos_df, lab_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dbe36e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df = pd.DataFrame(merged_data, columns=col_acc+[\"time_server_pos\"]+col_pos[1:]+[\"label\"])\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0865e8",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54937f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_columns_raw = [\"Gz\", \"Ax\", \"Ay\", 'POSx', 'POSy', 'orient', \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_reduced = raw_df[useful_columns_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = []\n",
    "fault_indexes = raw_df_reduced.index[raw_df_reduced[\"label\"] == 0].tolist() # list of indexes representing faults\n",
    "        \n",
    "previous = 0\n",
    "for fi in fault_indexes:\n",
    "    df_split.append(raw_df_reduced.iloc[previous:fi+1, :])\n",
    "    previous = fi + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(df_split)} faults, hence {len(df_split)} datasets.')\n",
    "for i, df_tmp in enumerate(df_split):\n",
    "    print(i, df_tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6822ee5a",
   "metadata": {},
   "source": [
    "## Features creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lens = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfs = []\n",
    "lag_features = []\n",
    "first = True\n",
    "\n",
    "for temps in df_split:\n",
    "    curr_w_len_data = []\n",
    "    for w_len in w_lens:\n",
    "\n",
    "        means = temps.rolling(w_len).mean()\n",
    "        cols = [t + \"_mean_w\" + str(w_len) for t in temps.columns]\n",
    "        means.columns = cols \n",
    "        curr_w_len_data.append(means)\n",
    "        if first:\n",
    "            lag_features.append(cols)\n",
    "        \n",
    "        stds = temps.rolling(w_len).std()\n",
    "        cols = [t + \"_std_w\" + str(w_len) for t in temps.columns]\n",
    "        stds.columns = cols\n",
    "        curr_w_len_data.append(stds)\n",
    "        if first:\n",
    "            lag_features.append(cols)\n",
    "\n",
    "        mins = temps.rolling(w_len).min()\n",
    "        cols = [t + \"_min_w\" + str(w_len) for t in temps.columns]\n",
    "        mins.columns = cols\n",
    "        curr_w_len_data.append(mins)\n",
    "        if first:\n",
    "            lag_features.append(cols)\n",
    "\n",
    "        maxs = temps.rolling(w_len).max()\n",
    "        cols = [t + \"_max_w\" + str(w_len) for t in temps.columns]\n",
    "        maxs.columns = cols\n",
    "        curr_w_len_data.append(maxs)\n",
    "        if first:\n",
    "            lag_features.append(cols)\n",
    "    \n",
    "    first = False\n",
    "\n",
    "    temps_diff = temps - temps.shift(1)\n",
    "    temps_diff.columns = [t + \"_diff\" for t in temps.columns]\n",
    "\n",
    "    df_with_nan = pd.concat([temps, temps_diff] + curr_w_len_data, axis=1)\n",
    "    df_curr = df_with_nan.dropna()\n",
    "\n",
    "    new_dfs.append(df_curr)\n",
    "\n",
    "df_new_features = new_dfs[0]\n",
    "for to_concat in new_dfs[1:]:\n",
    "    df_new_features = pd.concat([df_new_features, to_concat])\n",
    "    \n",
    "lag_features = [e for nested_lag_features in lag_features for e in nested_lag_features \n",
    "                if not e.startswith(\"POS\") and not e.startswith(\"orient\") and not e.startswith(\"label\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8600a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_features = ['Gz', 'Ax', 'Ay', 'Gz_diff', \n",
    "                  'Ax_diff', 'Ay_diff']\n",
    "differencing_features = point_features + lag_features\n",
    "new_features = differencing_features + ['POSx', 'POSy', 'orient', 'label']\n",
    "df_new_features = df_new_features[new_features]\n",
    "df_new_features = df_new_features.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c46370",
   "metadata": {},
   "source": [
    "## Handling seasonality with differencing over position and orientation\n",
    "\n",
    "### WARNING: Currently using POSx because of new trajectories. Also fixed_orient changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1285759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features[\"POSx\"].min(), df_new_features[\"POSx\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506771ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_pos = np.linspace(4.6, 15.9, 114)\n",
    "fixed_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the blue line is in the white area the AGV is moving forward or backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_new_features[\"orient\"]).plot()\n",
    "(df_new_features[\"POSx\"] * 100 - 1000).plot()\n",
    "\n",
    "x = np.linspace(0, 100000, 100)\n",
    "y1 = np.full_like(x, -45)  \n",
    "y2 = np.full_like(x, 45)  \n",
    "plt.fill_between(x, y1, y2, color='lightblue', alpha=0.5)\n",
    "\n",
    "x = np.linspace(0, 100000, 100)\n",
    "y1 = np.full_like(x, -135)  \n",
    "y2 = np.full_like(x, -180)  \n",
    "plt.fill_between(x, y1, y2, color='orange', alpha=0.5)\n",
    "\n",
    "x = np.linspace(0, 100000, 100)\n",
    "y1 = np.full_like(x, 135)  \n",
    "y2 = np.full_like(x, 180)  \n",
    "plt.fill_between(x, y1, y2, color='orange', alpha=0.5)\n",
    "\n",
    "plt.xlim((11000, 12000))\n",
    "plt.ylim((-600, 600))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features[\"orient\"].max(), df_new_features[\"orient\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dfe87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_orient = [[-135, -45], [45, 135]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features[\"orient_discr\"] = pd.Series([1 if (orient > fixed_orient[0][0] and orient < fixed_orient[0][1]) \n",
    "                                             else -1 if (orient > fixed_orient[1][0] or orient < fixed_orient[1][1]) \n",
    "                                             else 0 for orient in df_new_features[\"orient\"]])\n",
    "df_new_features[\"POSx_discr\"] = pd.Series([find_nearest(fixed_pos, curr_pos, return_index=False) \n",
    "                                           for curr_pos in df_new_features[\"POSx\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f672cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "differencing_dict = {feature: {} for feature in differencing_features}\n",
    "differencing_list = {feature: [] for feature in differencing_features}\n",
    "count_dict = {}\n",
    "\n",
    "for _, row in df_new_features.iterrows():\n",
    "    if row[\"label\"] >= margin:\n",
    "        keys = (row[\"orient_discr\"], row[\"POSx_discr\"])\n",
    "        if keys not in differencing_dict[\"Ax\"]:\n",
    "            for feature in differencing_features:\n",
    "                differencing_dict[feature][keys] = row[feature]\n",
    "            count_dict[keys] = 1\n",
    "        else:\n",
    "            for feature in differencing_features:\n",
    "                differencing_dict[feature][keys] += row[feature]\n",
    "            count_dict[keys] += 1\n",
    "\n",
    "for feature in differencing_features:\n",
    "    for keys in differencing_dict[\"Ax\"]:\n",
    "        differencing_dict[feature][keys] = differencing_dict[feature][keys] / count_dict[keys]\n",
    "    \n",
    "for _, row in df_new_features.iterrows():\n",
    "    for feature in differencing_features:\n",
    "        differencing_list[feature].append(row[feature] - differencing_dict[feature][(row[\"orient_discr\"], row[\"POSx_discr\"])])\n",
    "\n",
    "for feature in differencing_features:\n",
    "    df_new_features[\"differencing_\" + feature] = pd.Series(differencing_list[feature])\n",
    "\n",
    "df_new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266de57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_new_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4256e2f",
   "metadata": {},
   "source": [
    "## Features scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f79d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df_new_features), \n",
    "                  columns=list(df_new_features.columns))\n",
    "df = df.drop(columns=[\"label\", 'orient_discr','POSx_discr'])\n",
    "df[\"orient_discr\"] = df_new_features[\"orient_discr\"]\n",
    "df[\"POSx_discr\"] = df_new_features[\"POSx_discr\"]\n",
    "df[\"label\"] = df_new_features[\"label\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf52a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a22b7c",
   "metadata": {},
   "source": [
    "## Temporal delay analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb000f6",
   "metadata": {},
   "source": [
    "#### Time disalignments intra-datasets\n",
    "\n",
    "Collect all time differences between subsequent observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b18efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaps(df, are_labels=False):\n",
    "    gaps = []\n",
    "    for i in range(len(df) - 1):\n",
    "        if are_labels and df.loc[i, \"label\"] == \"s\":\n",
    "            gaps.append(df.loc[i + 1, \"time_server\"] - df.loc[i, \"time_server\"])\n",
    "        else:\n",
    "            gaps.append(df.loc[i + 1, \"time_server\"] - df.loc[i, \"time_server\"])\n",
    "    return gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67564a09",
   "metadata": {},
   "source": [
    "#### Accelerations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7558c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_gaps = get_gaps(acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aed30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_acc, max_acc, _, _ = describe(acc_gaps, list_quantiles=[0.5, 0.9, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(acc_gaps, bins=100)\n",
    "plt.xticks(np.arange(0, max_acc, round(max_acc / 25, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([g for g in acc_gaps if g < 1], bins=100)\n",
    "plt.xticks(np.arange(0, 1, round(1 / 25, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7306bb4",
   "metadata": {},
   "source": [
    "#### Positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_gaps = get_gaps(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pos, max_pos, _, _ = describe(pos_gaps, list_quantiles=[0.5, 0.9, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pos_gaps, bins=100)\n",
    "plt.xticks(np.arange(0, max_pos, round(max_pos / 25, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490438f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([g for g in pos_gaps if g < 1], bins=100)\n",
    "plt.xticks(np.arange(0, 1, round(1 / 25, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed582c",
   "metadata": {},
   "source": [
    "#### Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7bad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_gaps = get_gaps(lab_df, are_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lab, max_lab, _, _ = describe(lab_gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2449ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lab_gaps, bins=50)\n",
    "plt.xticks(np.arange(0, max_lab, round(max_lab / 25, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be08645",
   "metadata": {},
   "source": [
    "#### Time disalignments inter-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f784a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_td, max_td, _, _ = describe(time_disalignments, list_quantiles=[0.5, 0.9, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(time_disalignments, bins=100)\n",
    "plt.xticks(np.arange(0, max_td, round(max_td / 25, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([t for t in time_disalignments if t < 1], bins=100)\n",
    "plt.xticks(np.arange(0, 1, round(1 / 25, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebceeed",
   "metadata": {},
   "source": [
    "## Remaining useful life (RUL)\n",
    "\n",
    "The following plot shows the Remaining Useful Life (RUL), namely the number of time steps before that a failure occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"label\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f7598",
   "metadata": {},
   "source": [
    "## Data trends visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9bcaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_signal(df, feature):\n",
    "    plt.plot(df[feature], alpha=0.6)\n",
    "    plt.plot(df[\"POSx\"])\n",
    "    ranges = (df[\"label\"] == 0).map({True:0, False:30})\n",
    "    plt.scatter(range(len(df)), ranges, color=\"red\", s=20)\n",
    "    plt.ylim(-9,5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821422de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_signal_zoomed(df, feature):\n",
    "    for i in range(0, len(df) - 2000, 2000):\n",
    "        start = i\n",
    "        end = i + 2000\n",
    "        plt.plot(df[feature][start:end], alpha=0.6)\n",
    "        plt.plot(df[\"POSx\"][start:end])\n",
    "        ranges = (df[\"label\"] == 0).map({True:0, False:30})\n",
    "        plt.scatter(range(start, end), ranges[start:end], color=\"red\", s=20)\n",
    "        plt.ylim(-9, 5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8aa3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_only_faults(df, feature):\n",
    "    for i, is_fault in enumerate((df[\"label\"] == 0).tolist()):\n",
    "        if is_fault:\n",
    "            start = i - 20\n",
    "            end = i + 1\n",
    "            plt.plot(df[feature][start:end], alpha=0.6)\n",
    "            plt.plot(df[\"POSx\"][start:end])\n",
    "            ranges = (df[\"label\"] == 0).map({True:0, False:30})\n",
    "            plt.scatter(range(start, end), ranges[start:end], color=\"red\", s=20)\n",
    "            plt.ylim(-9, 5)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)  # select among these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"differencing_Ax_min_w5\"  # select feature to analyze here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc9eb5",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf1a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_signal(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2696093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_all_signal_zoomed(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_only_faults(df, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2463a89",
   "metadata": {},
   "source": [
    "## Data and constants storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/train/training_\" + str(margin) + \".csv\")\n",
    "\n",
    "with open('data/utils/scaler_' + str(margin) + '.bin', 'wb') as handle:\n",
    "    pickle.dump(scaler, handle)\n",
    "with open('data/utils/fixed_orient_' + str(margin) + '.bin', 'wb') as handle:\n",
    "    pickle.dump(fixed_orient, handle)\n",
    "with open('data/utils/fixed_pos_' + str(margin) + '.bin', 'wb') as handle:\n",
    "    pickle.dump(fixed_pos, handle)\n",
    "with open('data/utils/differencing_dict_' + str(margin) + '.bin', 'wb') as handle:\n",
    "    pickle.dump(differencing_dict, handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfb9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
