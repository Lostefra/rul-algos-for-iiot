{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d267c5c",
   "metadata": {},
   "source": [
    "# Data analysis and set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df02c22",
   "metadata": {},
   "source": [
    "## Import libraries and define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3375203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import floor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c34a05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = lambda l: sum(l) / len(l)\n",
    "\n",
    "def describe(l):\n",
    "    print(f'Min={min(l):.4}, Max={max(l):.4}, Avg={mean(l):.4}, Tot={len(l)}')\n",
    "    return min(l), max(l), mean(l), len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_info(f_path, seed, training_columns, params, history, best_cost, best_thr, all_cost, all_thr, perf):\n",
    "    to_serialize = (training_columns, params, history, best_cost, best_thr, all_cost, all_thr, perf)\n",
    "    with open(f_path + \"_\" + str(seed), \"wb\") as file:\n",
    "        pickle.dump(to_serialize, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b3b931",
   "metadata": {},
   "source": [
    "#### Set up global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0d48c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "plt.rcParams['figure.figsize'] = [18, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"results/\"\n",
    "seeds = [100, 200, 300, 400, 500, 600, 700, 800]\n",
    "\n",
    "def set_determinism(seed):\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 10\n",
    "df = pd.read_csv(\"data/train/training_\" + str(margin) + \".csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33610 rows in the dataset\n",
      "Index(['Gz', 'Ax', 'Ay', 'Gz_mean', 'Ax_mean', 'Ay_mean', 'Gz_min', 'Ax_min',\n",
      "       'Ay_min', 'Gz_max', 'Ax_max', 'Ay_max', 'Gz_diff', 'Ax_diff', 'Ay_diff',\n",
      "       'POSx', 'POSy', 'orient', 'differencing_Gz', 'differencing_Ax',\n",
      "       'differencing_Ay', 'differencing_Gz_mean', 'differencing_Ax_mean',\n",
      "       'differencing_Ay_mean', 'differencing_Gz_min', 'differencing_Ax_min',\n",
      "       'differencing_Ay_min', 'differencing_Gz_max', 'differencing_Ax_max',\n",
      "       'differencing_Ay_max', 'differencing_Gz_diff', 'differencing_Ax_diff',\n",
      "       'differencing_Ay_diff', 'orient_discr', 'POSy_discr', 'label'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gz</th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Gz_mean</th>\n",
       "      <th>Ax_mean</th>\n",
       "      <th>Ay_mean</th>\n",
       "      <th>Gz_min</th>\n",
       "      <th>Ax_min</th>\n",
       "      <th>Ay_min</th>\n",
       "      <th>Gz_max</th>\n",
       "      <th>...</th>\n",
       "      <th>differencing_Ay_min</th>\n",
       "      <th>differencing_Gz_max</th>\n",
       "      <th>differencing_Ax_max</th>\n",
       "      <th>differencing_Ay_max</th>\n",
       "      <th>differencing_Gz_diff</th>\n",
       "      <th>differencing_Ax_diff</th>\n",
       "      <th>differencing_Ay_diff</th>\n",
       "      <th>orient_discr</th>\n",
       "      <th>POSy_discr</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.6282</td>\n",
       "      <td>-0.1351</td>\n",
       "      <td>-0.2329</td>\n",
       "      <td>-0.7442</td>\n",
       "      <td>1.2804</td>\n",
       "      <td>1.1006</td>\n",
       "      <td>-0.4221</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>1.0306</td>\n",
       "      <td>-0.9778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>-0.1368</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.4715</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>-1.0597</td>\n",
       "      <td>-0.0789</td>\n",
       "      <td>1</td>\n",
       "      <td>20.6000</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.6079</td>\n",
       "      <td>1.1653</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>-0.7306</td>\n",
       "      <td>1.3201</td>\n",
       "      <td>1.0493</td>\n",
       "      <td>-0.4221</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>1.0306</td>\n",
       "      <td>-0.9572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>-0.1107</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.4715</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>1.2707</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>1</td>\n",
       "      <td>20.6000</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.5917</td>\n",
       "      <td>1.4625</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>-0.7158</td>\n",
       "      <td>1.4003</td>\n",
       "      <td>1.2590</td>\n",
       "      <td>-0.4221</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>1.2123</td>\n",
       "      <td>-0.9408</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1816</td>\n",
       "      <td>-0.1848</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>-0.0683</td>\n",
       "      <td>0.3254</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1</td>\n",
       "      <td>20.7000</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.5632</td>\n",
       "      <td>-0.0590</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>-0.6954</td>\n",
       "      <td>1.2243</td>\n",
       "      <td>1.4664</td>\n",
       "      <td>-0.4055</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>1.2123</td>\n",
       "      <td>-0.9119</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1816</td>\n",
       "      <td>-0.1483</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>-0.0136</td>\n",
       "      <td>-1.4467</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>1</td>\n",
       "      <td>20.7000</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5498</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>-0.5616</td>\n",
       "      <td>1.2194</td>\n",
       "      <td>1.4140</td>\n",
       "      <td>-0.4055</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>1.2123</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1583</td>\n",
       "      <td>1.1685</td>\n",
       "      <td>-0.0294</td>\n",
       "      <td>0.5793</td>\n",
       "      <td>4.7434</td>\n",
       "      <td>0.2389</td>\n",
       "      <td>-0.1707</td>\n",
       "      <td>1</td>\n",
       "      <td>20.8000</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gz      Ax      Ay  Gz_mean  Ax_mean  Ay_mean  Gz_min  Ax_min  Ay_min  \\\n",
       "0 -0.6282 -0.1351 -0.2329  -0.7442   1.2804   1.1006 -0.4221  0.8635  1.0306   \n",
       "1 -0.6079  1.1653  0.4926  -0.7306   1.3201   1.0493 -0.4221  0.8635  1.0306   \n",
       "2 -0.5917  1.4625  0.5144  -0.7158   1.4003   1.2590 -0.4221  0.8635  1.2123   \n",
       "3 -0.5632 -0.0590  0.9757  -0.6954   1.2243   1.4664 -0.4055  0.8635  1.2123   \n",
       "4  0.5498  0.2192  0.6788  -0.5616   1.2194   1.4140 -0.4055  0.8635  1.2123   \n",
       "\n",
       "   Gz_max  ...  differencing_Ay_min  differencing_Gz_max  differencing_Ax_max  \\\n",
       "0 -0.9778  ...               0.9950              -0.1368               0.0139   \n",
       "1 -0.9572  ...               0.9950              -0.1107               0.0139   \n",
       "2 -0.9408  ...               1.1816              -0.1848               0.1923   \n",
       "3 -0.9119  ...               1.1816              -0.1483               0.1923   \n",
       "4  0.2165  ...               1.1583               1.1685              -0.0294   \n",
       "\n",
       "   differencing_Ay_max  differencing_Gz_diff  differencing_Ax_diff  \\\n",
       "0               0.4715                0.0276               -1.0597   \n",
       "1               0.4715                0.0096                1.2707   \n",
       "2               0.4885               -0.0683                0.3254   \n",
       "3               0.4885               -0.0136               -1.4467   \n",
       "4               0.5793                4.7434                0.2389   \n",
       "\n",
       "   differencing_Ay_diff  orient_discr  POSy_discr  label  \n",
       "0               -0.0789             1     20.6000    960  \n",
       "1                0.5526             1     20.6000    959  \n",
       "2                0.0004             1     20.7000    958  \n",
       "3                0.3458             1     20.7000    957  \n",
       "4               -0.1707             1     20.8000    956  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df), \"rows in the dataset\")\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5765f47",
   "metadata": {},
   "source": [
    "# Machine learning: training phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d279553f",
   "metadata": {},
   "source": [
    "## Dataset preprocessing for machine learning models\n",
    "\n",
    "In this section, RUL labels are converted to binary labels (`0/1`, namely `not_fault/fault`) in order to perform classification instead of regression.\n",
    "\n",
    "For the `AutoEncoder` model, the dataset is partitioned such that the training set does not contain faults or samples which anticipate a fault. In other words, each sample must be compliant with the `good_samples_thr` threshold.\n",
    "\n",
    "We basically need an entire section of dataset where faults are not present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19cf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_for_ml_model(df, training_columns, split_size=0.75, as_list=False, ae=False):\n",
    "    dfs = []\n",
    "    df_main = df[training_columns]\n",
    "    fault_indexes = df_main.index[df_main[\"label\"] == 0].tolist() # list of indexes representing faults\n",
    "    good_samples_thr = margin * 2\n",
    "    \n",
    "    previous = 0\n",
    "    for fi in fault_indexes:\n",
    "        dfs.append(df_main.iloc[previous:fi+1, :])\n",
    "        previous = fi + 1\n",
    "    \n",
    "    rnd_list = list(range(len(dfs)))\n",
    "    # Disable the following istruction if you want to compare different models on same test data\n",
    "    # random.shuffle(rnd_list) \n",
    "    \n",
    "    # If split_size is 1, there will be no val/test set\n",
    "    train_size = floor(len(dfs) * split_size)\n",
    "    train_index = rnd_list[:train_size]\n",
    "    test_index = rnd_list[train_size:]\n",
    "    train_rul = []\n",
    "    test_rul = []\n",
    "    \n",
    "    if not as_list:\n",
    "        first = True\n",
    "        for ti in train_index:\n",
    "            if not ae:\n",
    "                to_concat = dfs[ti].copy()\n",
    "            else:\n",
    "                to_concat = dfs[ti][dfs[ti][\"label\"] >= good_samples_thr].copy()\n",
    "            if first:\n",
    "                training_set = to_concat\n",
    "                first = False\n",
    "            else:\n",
    "                training_set = pd.concat([training_set, to_concat])\n",
    "\n",
    "        first = True\n",
    "        for ti in test_index:\n",
    "            to_concat = dfs[ti].copy()\n",
    "            if first:\n",
    "                test_set = to_concat\n",
    "                first = False\n",
    "            else:\n",
    "                test_set = pd.concat([test_set, to_concat])\n",
    "        \n",
    "        train_rul = training_set['label'].tolist()\n",
    "        if split_size < 1:\n",
    "            test_rul = test_set['label'].tolist()\n",
    "        \n",
    "        training_set['label'] = (training_set['label'] >= margin).map({True: 1, False: 0})\n",
    "        if split_size < 1:\n",
    "            test_set['label'] = (test_set['label'] >= margin).map({True: 1, False: 0})\n",
    "\n",
    "        training_set = training_set.to_numpy()\n",
    "        if split_size < 1:\n",
    "            test_set = test_set.to_numpy()\n",
    "        \n",
    "    else:\n",
    "        first = True\n",
    "        for ti in train_index:\n",
    "            if not ae:\n",
    "                to_concat = dfs[ti].copy()\n",
    "            else:\n",
    "                to_concat = dfs[ti][dfs[ti][\"label\"] >= good_samples_thr].copy()\n",
    "            if first:\n",
    "                training_set = [to_concat]\n",
    "                first = False\n",
    "            else:\n",
    "                training_set.append(to_concat)\n",
    "                \n",
    "        first = True\n",
    "        for ti in test_index:\n",
    "            to_concat = dfs[ti].copy()\n",
    "            if first:\n",
    "                test_set = [to_concat]\n",
    "                first = False\n",
    "            else:\n",
    "                test_set.append(to_concat)\n",
    "        \n",
    "        for t in training_set:\n",
    "            train_rul = train_rul + t['label'].tolist()\n",
    "            t['label'] = (t['label'] >= margin).map({True: 1, False: 0})\n",
    "        if split_size < 1:\n",
    "            for t in test_set:\n",
    "                test_rul = test_rul + t['label'].tolist()\n",
    "                t['label'] = (t['label'] >= margin).map({True: 1, False: 0})\n",
    "    if split_size < 1:\n",
    "        return training_set, test_set\n",
    "    return training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c131072",
   "metadata": {},
   "source": [
    "## Cost model for threshold optimization and performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58986c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7551194",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FP = 0.2\n",
    "BASE_FN = 1\n",
    "\n",
    "def false_positive_cost(i, is_fault, fault_found):\n",
    "    return BASE_FP\n",
    "\n",
    "def false_negative_cost(i, is_fault, fault_found):\n",
    "    if not fault_found:\n",
    "        for j in range(1, margin + 1):\n",
    "            if i + j < is_fault.shape[0] and not is_fault[i + j] or i + j >= is_fault.shape[0]:\n",
    "                return (margin + 1 - j) * BASE_FN\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1359dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_optimization(signal, rul, start, end, n_steps):\n",
    "    best_cost = sys.maxsize\n",
    "    best_thr = -1\n",
    "    all_cost = []\n",
    "    all_thr = []\n",
    "    is_fault = (rul == 0)\n",
    "    \n",
    "    for thr in np.linspace(start, end, n_steps):\n",
    "        tmp_cost = 0\n",
    "        fault_found = False\n",
    "        for i in range(signal.shape[0]):\n",
    "            if is_fault[i] and signal[i] >= thr:\n",
    "                fault_found = True\n",
    "            if not is_fault[i]:\n",
    "                fault_found = False\n",
    "            if not is_fault[i] and signal[i] >= thr:\n",
    "                tmp_cost += false_positive_cost(i, is_fault, fault_found)\n",
    "            elif is_fault[i] and signal[i] <= thr:\n",
    "                tmp_cost += false_negative_cost(i, is_fault, fault_found)\n",
    "        if tmp_cost < best_cost:\n",
    "            best_thr = thr\n",
    "            best_cost = tmp_cost\n",
    "        all_cost.append(tmp_cost)\n",
    "        all_thr.append(thr)\n",
    "        \n",
    "    print(f'Best threshold: {best_thr:.3f}, best cost = {best_cost:.3f}')\n",
    "\n",
    "    return best_cost, best_thr, all_cost, all_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacfd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_threshold(signal, thr, rul):\n",
    "\n",
    "    plt.plot(signal, alpha=0.5)\n",
    "    plt.plot(range(len(signal)), [thr] * len(signal))\n",
    "\n",
    "    ranges = []\n",
    "    signal_values = []\n",
    "    for i in range(len(rul)):\n",
    "        if rul[i] == 0:\n",
    "            ranges.append(i)\n",
    "            signal_values.append(signal[i])\n",
    "\n",
    "    plt.scatter(ranges, signal_values, color=\"red\", s=10)\n",
    "    \n",
    "    plt.ylabel('Alarm signal intensity')\n",
    "    plt.xlabel('Time')\n",
    "    plt.legend(['Alarm signal', \"Threshold\", 'Anomalies'], loc='upper right')\n",
    "    plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_evaluation(signal, thr, rul):\n",
    "    fp, fn, tp, tot_p = 0, 0, 0, 0\n",
    "    cost = 0\n",
    "    alarm = (signal >= thr)\n",
    "    anticipation = []\n",
    "    is_fault = (rul == 0)\n",
    "    \n",
    "    fault_found = False\n",
    "    for i in range(len(rul)):\n",
    "        if i > 0 and is_fault[i] and not is_fault[i - 1]:\n",
    "            tot_p += 1\n",
    "            start = i\n",
    "        if is_fault[i] and not fault_found and alarm[i]:\n",
    "            tp += 1\n",
    "            fault_found = True\n",
    "            anticipation.append((margin - 1) - (i - start))\n",
    "        if (i < len(rul) - 1 and is_fault[i] and not is_fault[i + 1] and not fault_found) or (i == len(rul) - 1 and not fault_found):\n",
    "            fn += 1 \n",
    "        if is_fault[i] and signal[i] <= thr:\n",
    "            cost += false_negative_cost(i, is_fault, fault_found)\n",
    "        if not is_fault[i]:\n",
    "            fault_found = False\n",
    "            if alarm[i]:\n",
    "                fp += 1\n",
    "                cost += false_positive_cost(i, is_fault, fault_found)\n",
    "        \n",
    "    print(f'The total cost of the model is {cost:.3f}')\n",
    "    print(f'Detected {tp} faults over {tot_p}, missed faults: {fn}. False alarm: {fp}')\n",
    "    print(f'Faults detected with an anticipation of:')\n",
    "    for a in anticipation:\n",
    "        a = a / 10\n",
    "        print(f' - {a:.1f}s')\n",
    "    tot_a = sum(anticipation) / 10\n",
    "    if sum(anticipation) > 0:\n",
    "        mean_a = mean(anticipation) / 10\n",
    "    else:\n",
    "        mean_a = 0\n",
    "    print(f'The mean anticipation is {mean_a:.2f}s. Total amount of anticipation is {tot_a:.1f}s')\n",
    "    \n",
    "    return [cost, mean_a, tp, fn, fp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec634d",
   "metadata": {},
   "source": [
    "## Baseline: raw signal pre-anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a954fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_raw = ['Ax','Ax_mean', 'Ax_min', 'Ax_max', 'Ax_diff', \n",
    "                'differencing_Ax', 'differencing_Ax_mean', \n",
    "                'differencing_Ax_min', 'differencing_Ax_max', \n",
    "                'differencing_Ax_diff']\n",
    "\n",
    "for feature in features_raw:\n",
    "    training_columns = [feature, \"label\"]\n",
    "    _, validation_set_raw = build_dataset_for_ml_model(df, training_columns=training_columns)\n",
    "    val_raw_signal, val_raw_rul = -validation_set_raw[:, 0], validation_set_raw[:, -1]\n",
    "    best_cost_raw, best_thr_raw, all_cost_raw, all_thr_raw = threshold_optimization(val_raw_signal, val_raw_rul, start=0, end=val_raw_signal.max(), n_steps=200)\n",
    "    perf_raw = performance_evaluation(val_raw_signal, best_thr_raw, val_raw_rul)\n",
    "    all_perf.append([\"raw_signal\", training_columns, seed] + perf_raw)\n",
    "    # todo pensare come serializzare nome\n",
    "    serialize_info(f_path=results_path + \"\", seed=0, training_columns=feature, \n",
    "                   params={}, history, best_cost, best_thr, all_cost, all_thr, perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691254d9",
   "metadata": {},
   "source": [
    "## Pre-anomaly detection with AutoEncoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bfd398",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_ae, validation_set_ae = build_dataset_for_ml_model(df, ae=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(input_size, hidden):\n",
    "    input_shape = (input_size, )\n",
    "    ae_x = keras.Input(shape=input_shape, dtype='float32')\n",
    "    x = ae_x\n",
    "    for h in hidden:\n",
    "        x = layers.Dense(h, activation='relu')(x)\n",
    "    ae_y = layers.Dense(input_size, activation='linear')(x)\n",
    "    ae = keras.Model(ae_x, ae_y)   \n",
    "    \n",
    "    return ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols_ae = training_set_ae.shape[1] - 1\n",
    "params = {\"hidden_ae\": [16, 8, 2, 8, 16]}\n",
    "ae = build_autoencoder(input_size=train_cols_ae, hidden=hidden_ae)\n",
    "ae.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0001), \n",
    "           loss='mse')\n",
    "cb_ae = [callbacks.EarlyStopping(patience=30, restore_best_weights=True)]\n",
    "history_ae = ae.fit(training_set_ae[:, :-1], training_set_ae[:, :-1], validation_split=0.15,\n",
    "                    callbacks=cb_ae, batch_size=32, epochs=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee548cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ae = ae.predict(validation_set_ae[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a479fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ae = pd.Series(data=np.sum(np.square(preds_ae - validation_set_ae[:, :-1]), axis=1))\n",
    "rul_ae = validation_set_ae[:, -1]\n",
    "\n",
    "best_cost_ae, best_thr_ae, all_cost_ae, all_thr_ae = threshold_optimization(signal_ae, rul_ae, start=0, end=signal_ae.max(), n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eadf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(all_thr_ae, all_cost_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_threshold(signal_ae, best_thr_ae, rul_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ae = performance_evaluation(signal_ae, best_thr_ae, rul_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b28093",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perf.append([\"autoencoder\"] + perf_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d123add4",
   "metadata": {},
   "source": [
    "## RUL estimation with Dense Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_nn, validation_set_nn = build_dataset_for_ml_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(input_size, hidden):\n",
    "    input_shape = (input_size,)\n",
    "    model_in = keras.Input(shape=input_shape, dtype='float32')\n",
    "    x = model_in\n",
    "    for h in hidden:\n",
    "        x = layers.Dense(h, activation='relu')(x)\n",
    "    model_out = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(model_in, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad43d6",
   "metadata": {},
   "source": [
    "**Class weights** are useful when you have an **unbalanced dataset** and you want to improve single-label classification results. With class weights, you can weight more the samples belonging to the rarest class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_nn = pd.Series(training_set_nn[:, -1]).value_counts(normalize=True)\n",
    "class_weight_nn = {0: 1/counts_nn[0], 1: 1/counts_nn[1]}\n",
    "class_weight_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_nn = training_set_nn.shape[1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc4949",
   "metadata": {},
   "source": [
    "## Logistic Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab87f3",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab04484",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_cl = build_classifier(input_size=input_size_nn, hidden=[])\n",
    "lin_cl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c66160",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_cl.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "               loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657f91c",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1451441",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_lin = [callbacks.EarlyStopping(patience=30, restore_best_weights=True)]\n",
    "history_lin_cl = lin_cl.fit(training_set_nn[:, :-1], training_set_nn[:, -1], validation_split=0.2,\n",
    "                            callbacks=cb_lin, class_weight=class_weight_nn,\n",
    "                            batch_size=32, epochs=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0791666",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history_lin_cl, \"Logistic Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced74733",
   "metadata": {},
   "source": [
    "#### Threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lin_cl = lin_cl.predict(validation_set_nn[:, :-1]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c26e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_lin_cl = pd.Series(data=(1 - preds_lin_cl))\n",
    "rul_lin_cl = validation_set_nn[:, -1]\n",
    "\n",
    "best_cost_lin_cl, best_thr_lin_cl, all_cost_lin_cl, all_thr_lin_cl = threshold_optimization(signal_lin_cl, rul_lin_cl, start=0, end=signal_lin_cl.max(), n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca68325",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(all_thr_lin_cl, all_cost_lin_cl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f60f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_threshold(signal_lin_cl, best_thr_lin_cl, rul_lin_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e339ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_lin_cl = performance_evaluation(signal_lin_cl, best_thr_lin_cl, rul_lin_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perf.append([\"logistic_nn\"] + perf_lin_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e988dec",
   "metadata": {},
   "source": [
    "## Deep Dense Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc905b2f",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf58ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn = build_classifier(input_size=input_size_nn, hidden=[64, 32])\n",
    "ffnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "             loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5cec86",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97804d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_ffnn = [callbacks.EarlyStopping(patience=30, restore_best_weights=True)]\n",
    "history_ffnn = ffnn.fit(training_set_nn[:, :-1], training_set_nn[:, -1], validation_split=0.2,\n",
    "                        callbacks=cb_ffnn, \n",
    "                        class_weight=class_weight_nn,\n",
    "                        batch_size=32, epochs=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7273be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history_ffnn, \"Deep Dense Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71077ce2",
   "metadata": {},
   "source": [
    "#### Threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff71f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ffnn = ffnn.predict(validation_set_nn[:, :-1]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6019fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ffnn = pd.Series(data=(1 - preds_ffnn))\n",
    "rul_ffnn = validation_set_nn[:, -1]\n",
    "\n",
    "best_cost_ffnn, best_thr_ffnn, all_cost_ffnn, all_thr_ffnn = threshold_optimization(signal_ffnn, rul_ffnn, start=0, end=signal_ffnn.max(), n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(all_thr_ffnn, all_cost_ffnn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_threshold(signal_ffnn, best_thr_ffnn, rul_ffnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ffnn = performance_evaluation(signal_ffnn, best_thr_ffnn, rul_ffnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fcfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perf.append([\"deep_nn\"] + perf_ffnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed1a1bb",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1e0d6",
   "metadata": {},
   "source": [
    "#### Construct input as sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_2D(data, stride=1):\n",
    "    # Get shifted tables\n",
    "    m = len(data)\n",
    "    lt = [data.iloc[i:m-w_len+i+1:stride, :].values for i in range(w_len)]\n",
    "    # Reshape to add a new axis\n",
    "    s = lt[0].shape\n",
    "    for i in range(w_len):\n",
    "        lt[i] = lt[i].reshape(s[0], 1, s[1])\n",
    "    # Concatenate\n",
    "    wdata = np.concatenate(lt, axis=1)\n",
    "    return wdata\n",
    "\n",
    "\n",
    "def sliding_window_by_fault(data, cols, stride=1):\n",
    "    l_w, l_r = [], []\n",
    "    for gdata in data:\n",
    "        # Apply a sliding window\n",
    "        tmp_w = sliding_window_2D(gdata[cols], stride)\n",
    "        # Build the RUL vector\n",
    "        tmp_r = gdata['label'].iloc[w_len-1::stride]\n",
    "        # Store everything\n",
    "        l_w.append(tmp_w)\n",
    "        l_r.append(tmp_r)\n",
    "    res_w = np.concatenate(l_w)\n",
    "    res_r = np.concatenate(l_r)\n",
    "    return res_w, res_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e53a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_set_cnn, validation_set_cnn = build_dataset_for_ml_model(df, as_list=True)\n",
    "\n",
    "train_cols_cnn = ['differencing_Ax_mean', 'differencing_Gz_mean', 'differencing_Ay_mean']\n",
    "tr_sw, tr_sw_r = sliding_window_by_fault(traning_set_cnn, train_cols_cnn)\n",
    "val_sw, val_sw_r = sliding_window_by_fault(validation_set_cnn, train_cols_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some sequences\n",
    "tr_sw[0].shape, tr_sw_r[0], tr_sw[-1].shape, tr_sw_r[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65928226",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_cnn = tr_sw[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e8cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_cnn = pd.Series(tr_sw_r).value_counts(normalize=True)\n",
    "class_weight_cnn = {0: 1/counts_cnn[0], 1: 1/counts_cnn[1]}\n",
    "class_weight_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd138de",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_regressor(input_size, filters, kernel_size, hidden):\n",
    "    input_shape = (w_len, input_size)\n",
    "    model_in = keras.Input(shape=input_shape, dtype='float32')\n",
    "    model_out = layers.Conv1D(filters, kernel_size=kernel_size, \n",
    "                              activation='relu')(model_in)\n",
    "    model_out = layers.Flatten()(model_out)\n",
    "    for h in hidden:\n",
    "        model_out = layers.Dense(h, activation='relu')(model_out)\n",
    "    model_out = layers.Dense(1, activation='sigmoid')(model_out)\n",
    "    model = keras.Model(model_in, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b20311",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = build_cnn_regressor(input_size=input_size_cnn, filters=4,\n",
    "                          kernel_size=5, hidden=[64, 32])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f8ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "            loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b461dd",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_cnn = [callbacks.EarlyStopping(patience=30, restore_best_weights=True)]\n",
    "history_cnn = cnn.fit(tr_sw, tr_sw_r, validation_split=0.2,\n",
    "                      callbacks=cb_cnn,\n",
    "                      class_weight=class_weight_cnn,\n",
    "                      batch_size=32, epochs=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history_cnn, \"Convolutional Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd6c5f",
   "metadata": {},
   "source": [
    "#### Threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cnn = cnn.predict(val_sw).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb58292",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_cnn = pd.Series(data=(1 - preds_cnn))\n",
    "rul_cnn = val_sw_r\n",
    "\n",
    "best_cost_cnn, best_thr_cnn, all_cost_cnn, all_thr_cnn = threshold_optimization(signal_cnn, rul_cnn, start=0, end=signal_cnn.max(), n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23562a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(all_thr_cnn, all_cost_cnn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_threshold(signal_cnn, best_thr_cnn, rul_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6cf8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_cnn = performance_evaluation(signal_cnn, best_thr_cnn, rul_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perf.append([\"conv_nn\"] + perf_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9cffd",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c297fb4a",
   "metadata": {},
   "source": [
    "#### Construct input as sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346264c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D input\n",
    "def create_dataset_3D(X, y, time_steps = 1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-time_steps):\n",
    "        v = X[i:i+time_steps, :]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = margin\n",
    "\n",
    "traning_set_rnn, validation_set_rnn = build_dataset_for_ml_model(df)\n",
    "X_train_rnn, y_train_rnn = create_dataset_3D(traning_set_rnn[:, :-1], \n",
    "                                             traning_set_rnn[:, -1], \n",
    "                                             TIME_STEPS)\n",
    "X_val_rnn, y_val_rnn = create_dataset_3D(validation_set_rnn[:, :-1], \n",
    "                                         validation_set_rnn[:, -1],   \n",
    "                                         TIME_STEPS)\n",
    "print('X_train_rnn.shape: ', X_train_rnn.shape)\n",
    "print('y_train_rnn.shape: ', y_train_rnn.shape)\n",
    "print('X_val_rnn.shape: ', X_val_rnn.shape)\n",
    "print('y_val_rnn.shape: ', y_val_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c25bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_rnn = pd.Series(tr_sw_r).value_counts(normalize=True)\n",
    "class_weight_rnn = {0: 1/counts_rnn[0], 1: 1/counts_rnn[1]}\n",
    "class_weight_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba908d",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BiLSTM model for classification\n",
    "def create_model_bilstm_cl(units, X_train, lr=0.0001):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=units,                             \n",
    "              return_sequences=True),\n",
    "              input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=units)))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    #Compile model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "    return model\n",
    "\n",
    "# Create LSTM or GRU model\n",
    "def create_model_cl(units, m, X_train, lr=0.0001):\n",
    "    model = keras.Sequential()\n",
    "    model.add(m (units = units, return_sequences = True,\n",
    "                input_shape = [X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(m (units = units))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(units = 1, activation=\"sigmoid\"))\n",
    "    #Compile model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM\n",
    "model_bilstm = create_model_bilstm_cl(64, X_train_rnn)\n",
    "# GRU and LSTM\n",
    "model_gru = create_model_cl(64, keras.layers.GRU, X_train_rnn)\n",
    "model_lstm = create_model_cl(64, keras.layers.LSTM, X_train_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2049e49",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38981d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, name, X_train, y_train, pat=12, ep=1000, bs=32):\n",
    "        print(\"\\n\", name)\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                   patience=pat)\n",
    "        history = model.fit(X_train, y_train, epochs=ep,\n",
    "                            class_weight=class_weight_rnn,\n",
    "                            validation_split=0.2, batch_size=bs,\n",
    "                            shuffle=False, callbacks=[early_stop])\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b171f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_bilstm = fit_model(model_bilstm, \"model_bilstm\", X_train_rnn, y_train_rnn)\n",
    "history_lstm = fit_model(model_lstm, \"model_lstm\", X_train_rnn, y_train_rnn)\n",
    "history_gru = fit_model(model_gru, \"model_gru\", X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693543f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss(history_bilstm, \"model_bilstm\")\n",
    "plot_loss(history_lstm, \"model_lstm\")\n",
    "plot_loss(history_gru, \"model_gru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d53a4c",
   "metadata": {},
   "source": [
    "#### Threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccdd02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_bilstm = model_bilstm.predict(X_val_rnn).ravel()\n",
    "preds_lstm = model_lstm.predict(X_val_rnn).ravel()\n",
    "preds_gru = model_gru.predict(X_val_rnn).ravel()\n",
    "\n",
    "signal_bilstm = pd.Series(data=(1 - preds_bilstm))\n",
    "rul_bilstm = y_val_rnn\n",
    "signal_lstm = pd.Series(data=(1 - preds_lstm))\n",
    "rul_lstm = y_val_rnn\n",
    "signal_gru = pd.Series(data=(1 - preds_gru))\n",
    "rul_gru = y_val_rnn\n",
    "\n",
    "best_cost_bilstm, best_thr_bilstm, all_cost_bilstm, all_thr_bilstm = threshold_optimization(signal_bilstm, rul_bilstm, start=0, end=signal_bilstm.max(), n_steps=200)\n",
    "best_cost_lstm, best_thr_lstm, all_cost_lstm, all_thr_lstm = threshold_optimization(signal_lstm, rul_lstm, start=0, end=signal_lstm.max(), n_steps=200)\n",
    "best_cost_gru, best_thr_gru, all_cost_gru, all_thr_gru = threshold_optimization(signal_gru, rul_gru, start=0, end=signal_gru.max(), n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571da876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(all_thr_bilstm, all_cost_bilstm)\n",
    "plt.show()\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(all_thr_lstm, all_cost_lstm)\n",
    "plt.show()\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(all_thr_gru, all_cost_gru)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da30144",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_threshold(signal_bilstm, best_thr_bilstm, rul_bilstm)\n",
    "plot_threshold(signal_lstm, best_thr_lstm, rul_lstm)\n",
    "plot_threshold(signal_gru, best_thr_gru, rul_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48167094",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bi-LSTM:\")\n",
    "perf_bilstm = performance_evaluation(signal_bilstm, best_thr_bilstm, rul_bilstm)\n",
    "print(\"\\nLSTM:\")\n",
    "perf_lstm = performance_evaluation(signal_lstm, best_thr_lstm, rul_lstm)\n",
    "print()\n",
    "print(\"\\nGRU:\")\n",
    "perf_gru = performance_evaluation(signal_gru, best_thr_gru, rul_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perf.append([\"bilstm\"] + perf_bilstm)\n",
    "all_perf.append([\"lstm\"] + perf_lstm)\n",
    "all_perf.append([\"gru\"] + perf_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c74558",
   "metadata": {},
   "source": [
    "## Analysis over the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_perf, columns=[\"model\", \"cost\", \"anticipation\", \"detected_faults\", \"missed_faults\", \"false_alarms\"]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
